#
# Copyright 2014 eNovance
#
# Authors: Julien Danjou <julien@danjou.info>
#          Mehdi Abaakouk <mehdi.abaakouk@enovance.com>
#
# Licensed under the Apache License, Version 2.0 (the "License"); you may
# not use this file except in compliance with the License. You may obtain
# a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
from __future__ import absolute_import

import copy
import fnmatch
import itertools
import json
import operator
import os

from ceilometer import dispatcher
from ceilometer.i18n import _
from keystoneclient.v2_0 import client as ksclient
from oslo.config import cfg
from oslo_log import log
import requests
import six
import stevedore.dispatch
import yaml

LOG = log.getLogger(__name__)

dispatcher_opts = [
    cfg.BoolOpt('filter_service_activity',
                default=True,
                help='Filter out samples generated by Gnocchi '
                'service activity'),
    cfg.StrOpt('filter_user',
               default='gnocchi',
               help='Gnocchi user used to filter out samples '
               'generated by Gnocchi service activity'),
    cfg.StrOpt('url',
               default="http://localhost:8041",
               help='URL to Gnocchi.'),
    cfg.StrOpt('archive_policy_rules_file',
               default="ap_rules.yaml",
               help='Path to yaml file with archive policies rules '
                    'definitions.')
]

cfg.CONF.register_opts(dispatcher_opts, group="dispatcher_gnocchi")
cfg.CONF.import_group('service_credentials', 'ceilometer.service')


class UnexpectedWorkflowError(Exception):
    pass


class NoSuchMetric(Exception):
    pass


class MetricAlreadyExists(Exception):
    pass


class NoSuchResource(Exception):
    pass


class ResourceAlreadyExists(Exception):
    pass


def log_and_ignore_unexpected_workflow_error(func):
    def log_and_ignore(*args, **kwargs):
        try:
            func(*args, **kwargs)
        except UnexpectedWorkflowError as e:
            LOG.error(six.text_type(e))
    return log_and_ignore


class GnocchiDispatcher(dispatcher.Base):
    def __init__(self, conf):
        super(GnocchiDispatcher, self).__init__(conf)
        self.filter_service_activity = (
            conf.dispatcher_gnocchi.filter_service_activity)

        self._ks_client = ksclient.Client(
            username=conf.service_credentials.os_username,
            password=conf.service_credentials.os_password,
            tenant_id=conf.service_credentials.os_tenant_id,
            tenant_name=conf.service_credentials.os_tenant_name,
            cacert=conf.service_credentials.os_cacert,
            auth_url=conf.service_credentials.os_auth_url,
            region_name=conf.service_credentials.os_region_name,
            insecure=conf.service_credentials.insecure)

        if self.filter_service_activity:
            try:
                self.gnocchi_user_id = self._ks_client.users.find(
                    name=conf.dispatcher_gnocchi.filter_user)
            except Exception:
                LOG.exception('fail to retreive user of Gnocchi service')
                raise

        self.gnocchi_url = conf.dispatcher_gnocchi.url
        # NOTE(dbelova): later this might be managed via persistent config
        # and pipeline storage we do have for Ceilometer being in development
        self.gnocchi_archive_policy_rules = self._parse_ap_config()
        self.mgmr = stevedore.dispatch.DispatchExtensionManager(
            'gnocchi.ceilometer.resource', lambda x: True,
            invoke_on_load=True)

    def _parse_ap_config(self):
        """Parse yaml file with archive policies rules."""
        cfg_file = cfg.CONF.dispatcher_gnocchi.archive_policy_rules_file
        if not os.path.exists(cfg_file):
            cfg_file = cfg.CONF.find_file(cfg_file)

        LOG.debug(_("Archive policies rules file: %s"), cfg_file)

        with open(cfg_file) as fap:
            data = fap.read()

        archive_rules = yaml.safe_load(data)
        LOG.info(_("Archive rules: %s"), archive_rules)

        for archive_policy in archive_rules:
            r = requests.patch(
                "%s/v1/archive_policy/%s/%s"
                % (self.gnocchi_url, archive_policy['name'], 'rules'),
                headers=self._get_headers(),
                data=json.dumps(archive_policy['rules']))

            if int(r.status_code / 100) != 2:
                raise UnexpectedWorkflowError(
                    _("Archive policy %(name)s update failed with "
                      "status: %(status_code)d: %(msg)s") %
                    {'name': archive_policy['name'],
                     'status_code': r.status_code,
                     'msg': r.text})

        return archive_rules

    def _get_metric_ap(self, metric_name, resource_attributes):
        filters = copy.deepcopy(resource_attributes)
        filters.pop('metrics')
        filters['metric_name'] = metric_name

        # NOTE(dbelova): I've decided to use order we've listed archive
        # policies as the priority parameter. So default policy should be
        # listed last, more concrete ones - first.
        # I would say default section should look like as following:
        #
        #       - name: low
        #         rules:
        #           - metric_name: "*"

        for ap in self.gnocchi_archive_policy_rules['archive_policies']:
            policy_name = ap['name']
            for rule, value in six.iteritems(ap['rules']):
                if rule in filters and fnmatch.fnmatch(value, filters[rule]):
                    return policy_name

    def _get_headers(self, content_type="application/json"):
        return {
            'Content-Type': content_type,
            'X-Auth-Token': self._ks_client.auth_token,
        }

    def _is_gnocchi_activity(self, sample):
        return (self.filter_service_activity
                and sample['user_id'] == self.gnocchi_user_id)

    def record_metering_data(self, data):
        # NOTE(sileht): skip sample generated by gnocchi itself
        data = [s for s in data if not self._is_gnocchi_activity(s)]

        # FIXME(sileht): This method bulk the processing of samples
        # grouped by resource_id and metric_name but this is not
        # efficient yet because the data received here doesn't often
        # contains a lot of different kind of samples
        # So perhaps the next step will be to pool the received data from
        # message bus.

        resource_grouped_samples = itertools.groupby(
            data, key=operator.itemgetter('resource_id'))

        for resource_id, samples_of_resource in resource_grouped_samples:
            resource_need_to_be_updated = True

            metric_grouped_samples = itertools.groupby(
                list(samples_of_resource),
                key=operator.itemgetter('counter_name'))
            for metric_name, samples in metric_grouped_samples:
                for ext in self.mgmr:
                    if metric_name in ext.obj.get_metrics_names():
                        self._process_samples(
                            ext, resource_id, metric_name, list(samples),
                            resource_need_to_be_updated)

                # FIXME(sileht): Does it reasonable to skip the resource
                # update here ? Does differents kind of counter_name
                # can have different metadata set ?
                # (ie: one have only flavor_id, and an other one have only
                # image_ref ?)
                #
                # resource_need_to_be_updated = False

    @log_and_ignore_unexpected_workflow_error
    def _process_samples(self, ext, resource_id, metric_name, samples,
                         resource_need_to_be_updated):

        resource_type = ext.name
        measure_attributes = [{'timestamp': sample['timestamp'],
                               'value': sample['counter_volume']}
                              for sample in samples]

        try:
            self._post_measure(resource_type, resource_id, metric_name,
                               measure_attributes)
        except NoSuchMetric:
            # NOTE(sileht): we try first to create the resource, because
            # they more chance that the resource doesn't exists than the metric
            # is missing, the should be reduce the number of resource API call
            resource_attributes = self._get_resource_attributes(
                ext, resource_id, metric_name, samples)
            try:
                self._create_resource(resource_type, resource_id,
                                      resource_attributes)
            except ResourceAlreadyExists:
                try:
                    archive_policy_name = self._get_metric_ap(
                        metric_name, resource_attributes)
                    self._create_metric(resource_type, resource_id,
                                        metric_name, archive_policy_name)
                except MetricAlreadyExists:
                    # NOTE(sileht): Just ignore the metric have been created in
                    # the meantime.
                    pass
            else:
                # No need to update it we just created it
                # with everything we need
                resource_need_to_be_updated = False

            # NOTE(sileht): we retry to post the measure but if it fail we
            # don't catch the exception to just log it and continue to process
            # other samples
            self._post_measure(resource_type, resource_id, metric_name,
                               measure_attributes)

        if resource_need_to_be_updated:
            resource_attributes = self._get_resource_attributes(
                ext, resource_id, metric_name, samples, for_update=True)
            self._update_resource(resource_type, resource_id,
                                  resource_attributes)

    def _get_resource_attributes(self, ext, resource_id, metric_name, samples,
                                 for_update=False):
        # FIXME(sileht): Should I merge attibutes of all samples ?
        # Or keep only the last one is sufficient ?
        attributes = ext.obj.get_resource_extra_attributes(
            samples[-1])
        if not for_update:
            attributes["id"] = resource_id
            attributes["user_id"] = samples[-1]['user_id']
            attributes["project_id"] = samples[-1]['project_id']
            archive_policy_name = self._get_metric_ap(metric_name, attributes)
            attributes["metrics"] = dict(
                (metric_name, archive_policy_name)
                for metric_name in ext.obj.get_metrics_names()
            )
        return attributes

    def _post_measure(self, resource_type, resource_id, metric_name,
                      measure_attributes):
        r = requests.post("%s/v1/resource/%s/%s/metric/%s/measures"
                          % (self.gnocchi_url, resource_type, resource_id,
                             metric_name),
                          headers=self._get_headers(),
                          data=json.dumps(measure_attributes))
        if r.status_code == 404:
            LOG.debug(_("The metric %(metric_name)s of "
                        "resource %(resource_id)s doesn't exists"
                        "%(status_code)d"),
                      {'metric_name': metric_name,
                       'resource_id': resource_id,
                       'status_code': r.status_code})
            raise NoSuchMetric
        elif int(r.status_code / 100) != 2:
            raise UnexpectedWorkflowError(
                _("Fail to post measure on metric %(metric_name)s of "
                  "resource %(resource_id)s with status: "
                  "%(status_code)d: %(msg)s") %
                {'metric_name': metric_name,
                 'resource_id': resource_id,
                 'status_code': r.status_code,
                 'msg': r.text})
        else:
            LOG.debug("Measure posted on metric %s of resource %s",
                      metric_name, resource_id)

    def _create_resource(self, resource_type, resource_id,
                         resource_attributes):
        r = requests.post("%s/v1/resource/%s"
                          % (self.gnocchi_url, resource_type),
                          headers=self._get_headers(),
                          data=json.dumps(resource_attributes))
        if r.status_code == 409:
            LOG.debug("Resource %s already exists", resource_id)
            raise ResourceAlreadyExists

        elif int(r.status_code / 100) != 2:
            raise UnexpectedWorkflowError(
                _("Resource %(resource_id)s creation failed with "
                  "status: %(status_code)d: %(msg)s") %
                {'resource_id': resource_id,
                 'status_code': r.status_code,
                 'msg': r.text})
        else:
            LOG.debug("Resource %s created", resource_id)

    def _update_resource(self, resource_type, resource_id,
                         resource_attributes):
        r = requests.patch(
            "%s/v1/resource/%s/%s"
            % (self.gnocchi_url, resource_type, resource_id),
            headers=self._get_headers(),
            data=json.dumps(resource_attributes))

        if int(r.status_code / 100) != 2:
            raise UnexpectedWorkflowError(
                _("Resource %(resource_id)s update failed with "
                  "status: %(status_code)d: %(msg)s") %
                {'resource_id': resource_id,
                 'status_code': r.status_code,
                 'msg': r.text})
        else:
            LOG.debug("Resource %s updated", resource_id)

    def _create_metric(self, resource_type, resource_id, metric_name,
                       archive_policy_name):
        params = {metric_name: {'archive_policy_name': archive_policy_name}}
        r = requests.post("%s/v1/resource/%s/%s/metric"
                          % (self.gnocchi_url, resource_type,
                             resource_id),
                          headers=self._get_headers(),
                          data=json.dumps(params))
        if r.status_code == 409:
            LOG.debug("Metric %s of resource %s already exists",
                      metric_name, resource_id)
            raise MetricAlreadyExists

        elif int(r.status_code / 100) != 2:
            raise UnexpectedWorkflowError(
                _("Fail to create metric %(metric_name)s of "
                  "resource %(resource_id)s with status: "
                  "%(status_code)d: %(msg)s") %
                {'metric_name': metric_name,
                 'resource_id': resource_id,
                 'status_code': r.status_code,
                 'msg': r.text})
        else:
            LOG.debug("Metric %s of resource %s created",
                      metric_name, resource_id)

    @staticmethod
    def record_events(events):
        raise NotImplementedError
